{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "fd92ffde",
      "metadata": {},
      "source": [
        "TODO\n",
        "1. extract features by googlenet\n",
        "2. compute similarity\n",
        "3. test on Place dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "52812333",
      "metadata": {},
      "outputs": [],
      "source": [
        "# load places205 dataset\n",
        "# import hub\n",
        "# ds = hub.load(\"hub://activeloop/places205\")\n",
        "# dataloader = ds.pytorch(num_workers = 2, shuffle = False, batch_size= 4)\n",
        "\n",
        "# import numpy as np\n",
        "# img = ds.images[42].numpy()\n",
        "# print(img.shape)\n",
        "\n",
        "# import matplotlib.pyplot as plt\n",
        "# plt.imshow(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "e8fa50a8",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torch.utils.hooks.RemovableHandle at 0x1af30a18d90>"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from googlenet_places205 import GoogLeNetPlaces205\n",
        "\n",
        "model = GoogLeNetPlaces205()\n",
        "model.load_state_dict(torch.load(\"googlenet_places205.pth\"))\n",
        "\n",
        "# define hook\n",
        "features = {}\n",
        "def get_middle_output(name):\n",
        "    def hook(model, input, output):\n",
        "        features[name] = (output.detach())\n",
        "    return hook\n",
        "\n",
        "# model.inception_3b_5x5.register_forward_hook(get_middle_output('icp1'))\n",
        "model.inception_4b_5x5.register_forward_hook(get_middle_output('icp1'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "a5262180",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "\n",
        "def preprocess_singe_img(filename):\n",
        "    input_image = Image.open(filename)\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "    input_tensor = transform(input_image)\n",
        "    input_batch = input_tensor.unsqueeze(0) # create a mini-batch as expected by the model\n",
        "    return input_batch\n",
        "\n",
        "def get_features(input):\n",
        "    output = model(input)\n",
        "    return features['icp1'].flatten()\n",
        "\n",
        "def get_similarity(input1, input2):\n",
        "    cos = nn.CosineSimilarity(dim=0, eps=1e-6)\n",
        "    return cos(input1, input2)\n",
        "\n",
        "\n",
        "def process_images_from_folder(folder):\n",
        "    image_features = []\n",
        "    for filename in os.listdir(folder):\n",
        "        if filename is not None:\n",
        "            input = preprocess_singe_img(folder + '/' + filename)\n",
        "            image_features.append(get_features(input))\n",
        "    return image_features\n",
        "\n",
        "# filename = [\"images/road.png\", \"images/road2.png\", \"images/rail.png\", \"images/rail2.png\"]\n",
        "# outputs = []\n",
        "# for img in filename:\n",
        "#     input = preprocess(img)\n",
        "#     outputs.append(get_features(input))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "6341d2fb",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([-1.3158, -2.0469, -2.1182,  ...,  3.9142,  3.5797,  3.1912])\n",
            "tensor([-1.2194, -1.7579, -1.6108,  ...,  3.6001,  3.4171,  3.1232])\n",
            "[[0.90076178 0.88163835 0.87797463 0.89589965 0.86852586 0.9068318\n",
            "  0.90239567 0.89438421 0.87929589 0.89844006]\n",
            " [0.8977223  0.89657336 0.88530189 0.90753168 0.87957031 0.90492189\n",
            "  0.90046072 0.89172792 0.8838402  0.90702587]\n",
            " [0.89282602 0.88042587 0.87665522 0.89696538 0.86917925 0.91075933\n",
            "  0.91158795 0.89736629 0.88143718 0.90064716]\n",
            " [0.89534479 0.88059169 0.87750459 0.89731002 0.86872315 0.91105425\n",
            "  0.91323161 0.90013766 0.88387418 0.90176362]\n",
            " [0.90983176 0.8957417  0.89488769 0.90974045 0.88164067 0.9240213\n",
            "  0.92625242 0.91371489 0.89778656 0.91378891]\n",
            " [0.89913219 0.88031209 0.88222921 0.89834303 0.86958474 0.91152889\n",
            "  0.91242987 0.89911371 0.88263708 0.89947456]\n",
            " [0.89584845 0.87162364 0.87684631 0.89176923 0.86093408 0.9050982\n",
            "  0.90351647 0.891101   0.8749907  0.89198327]\n",
            " [0.89071667 0.86750412 0.87093419 0.88755512 0.85755229 0.90305138\n",
            "  0.89975584 0.88633859 0.87021869 0.88840568]\n",
            " [0.88888007 0.86332941 0.86902118 0.88397908 0.85203272 0.89516312\n",
            "  0.89488202 0.88162225 0.86466742 0.88387412]\n",
            " [0.8881911  0.87047642 0.86835462 0.88561547 0.85878342 0.90281707\n",
            "  0.90425974 0.89026397 0.87273014 0.89169282]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "database = \"images/database\"\n",
        "query = \"images/query\"\n",
        "\n",
        "database_features = process_images_from_folder(database)\n",
        "query_features = process_images_from_folder(query)\n",
        "\n",
        "similarity_matrix = np.zeros((len(query), len(database_features))) # Q by D\n",
        "\n",
        "for i in range(len(query_features)):\n",
        "    for j in range(len(database_features)):\n",
        "        similarity_matrix[i][j] = get_similarity(query_features[i], database_features[j])\n",
        "\n",
        "# print(query_features[9])\n",
        "# print(database_features[9])\n",
        "print(similarity_matrix)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "pytorch_vision_googlenet.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "5d41c24aa7bc539c1e5b2b8472fb4f5e6fdc1aae223a5e4e26647df085f4bdf4"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 ('d2l')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
